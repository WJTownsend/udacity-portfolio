# Udacity Data Wrangling Review
**Format:** Each of the Udacity classes consists of several lessons, each with a number of "concepts". Instruction is generally provided in short (1-6 minutes) videos, sometimes with supporting text. Video instruction is often followed with supplemental text, if needed, and practical exercises using plugins to the Udacity site. This allows students to perform operations demonstrated in the video lecture without installing additional software on their own computers. Quizzes usually accompany these practical exercises to provide a "check" that students are executing the demonstrated concepts correctly. 

**Prior Experience With Subject:** I had some very basic ideas and knowledge about data wrangling from building various spreadsheets or small databases in Excel for prior jobs, but nothing on the level of this class. Most of the knowledge and experience that I had that was relevant here was from the Intro to Data Analysis class, earlier in the program. In that project in particular, I had to learn a LOT about doing data wrangling and finding ways to correct a wide variety of issues in a dataset. 

## Class Grade (1-10): **3**
This class is broken into three basic chunks: gathering data, assessing data, and cleaning data. Throughout the Udacity program, students to this point have used datasets provided by Udacity in different formats, but the data gathering portion of the class introduced web scraping as a new way to gather data. I was excited about this because it would really expand my abilities to work with new datasets, but I was very frustrated by what what I felt was a very perfunctory and incomplete training on scraping and the usage of APIs. 

This lesson on data gathering went from a really, really basic example to a really complex example, without breaking down and explaining how and why that complex example worked, so I ended up having to do other research to understand the material presented in the class. Throughout this class (and most egregiously in the data gathering portion) the class would only passingly reference or explain something in the course, providing links instead to documentation or StackOverflow questions of varying quality. As addressed in other reviews that I've written, this is a problem because if all a student needed to learn how to do something difficult was the readme, they wouldn't need Udacity or other training materials, tech employers would have all of the employees they need, and the tech gap wouldn't exist! On a few other occasions, the course would acknowledge that it wasn't explaining something inside of the course itself and would instead link to outside resources, often linking to portions of other educational packages. Aside from the potential concerns that this generates regarding Udacity's monetization of someone else's work, this also leaves Udacity vulnerable to link rot (this will be a theme of this review), and when combined with the other frustrations present in the back half of the DAND program, it makes the student wonder aloud, "What, exactly, am I paying *you* for?".

The nature of the course also involved having to access data from other sites, such as the WikiMedia API, for gathering certain data. This reliance makes the course prone to link rot, such as when one of the course quizzes on data gathering (the concept that is most "new" at this point in the NanoDegree) was broken due to an update to the WikiMedia API. Notice of this is not present in the quiz itself, leaving students to work ineffectually to understand something that is broken, until they finally go to the Knowledge Forum and find that this has been a known issue for months that has not yet been corrected by their content team. This is a great demonstration of the perils of link rot and Udacity's reliance on using other resources. Unfortunately, this was not the only example of broken or incorrect information being provided. In the data cleaning quizzes in particular, I found multiple issues where the cleaning process was done poorly, in ways that removed items from the dataset without acknowledgement or apparent intent to do so. On at least one occasion, this sort of issue was noticed and a check added to see if data had been mistakenly excluded, but this check was included *after* the cleaning operation which would remove that data, so the check became useless. This was frustrating to me, because the sort of critical thinking and attention to detail is absolutely vital to proper data cleaning and analysis. 

## Project Grade (1-10): **4**
### Project: *Wrangle and Analyze Data*
### Number of times project was kicked back for changes: **0**
This project was actually in many ways quite interesting and enjoyable, as it required students to analyze a large amount of data from the [WeRateDogs twitter account](https://twitter.com/dog_rates). This idea really should've led to a 10/10 project, but it really came up short because of how awful the start of this project was, where data is gathered from the Twitter API after the course failed to adequately teach this concept. The project specifically requires students to use the tweepy and json libraries for generating their data (ideally by getting developer access to the Twitter API, though a workaround is present for those unable to do so), despite never having used either of these libraries in the course preceding the project. The json library is briefly referenced in the aforementioned broken quiz in another link to someone else's tutorial, but tweepy is only given a link to the library's documentation. There is very little explanation of what to do for any of this, though some of this can be found via the Knowledge Forum and code posted there, which can allow students to reverse engineer what exactly is supposed to be happening in this first portion of the project and how to generate their data.

Speaking of the Knowledge Forum, while this is generally a very useful (if poorly organized) resource for students, I had a noticeably harder time using the Knowledge Forum for this project than I did other projects. Some of this seemed to be because of the sheer number of questions about not understanding the 'gathering' portion of the project, which anecdotally seemed to be a larger particular issue for this class than any issue that I saw in my other Udacity classes. However, this was compounded by a reliance from several of the Mentors (Udacity staff) on not answering questions in the Knowledge Forum but instead providing links to other external tutorials. Unfortunately, where a "really interesting tutorial on the Twitter API" had previously existed, these links now often went to services like "buy our social media business plugin for $299!" or "Tell us what data you need scraped from Twitter and we'll do it for a price!". Again, this is a great example of why Udacity should be generating some of these tutorials themselves (aside from the fact that students are paying Udacity to educate them).  Most of the occasions where I saw these issues with link rot were 6 - 24 months old (and seemed to come from a couple of particular mentors), but this is itself an issue, as Udacity has chosen to leave this non-content up for newer students to have to sift through in order to find the useful content. 

Once I was through this early portion of data gathering for the project, I actually had a lot of fun with it, largely because reading silly tweets about dogs and treating them as srs bsns is a lot of fun. I really liked that this let me take a lighthearted approach to data analysis and make some silly jokes inside of a class project. I ended up going quite far on it (where we only had to correct 10 data issues, I did nearly twice that) and probably spent more time on it than I should've, but it was a nice change of pace. As I said, its unfortunate that the beginning of the project was so poorly constructed and explained, because the rest of it really was pretty good. 

## Overall Grade (1-10): **3**
As mentioned above, I was actually really looking forward to this class. I had learned a lot about data wrangling through my previous projects in the DAND program, but I also knew that I had really only learned about cleaning/formatting my data for the purposes of facilitating analysis. Gathering data was going to be a big step into something that I'd not previously done but that I recognized was a hugely powerful tool that would allow me to start doing things on my own, rather than relying on someone else to get me started by scraping data into a .csv for me. How poorly this course then went about teaching this and the overt and obvious problems which Udacity has chosen to ignore was really disappointing. I really didn't learn much at all about scraping and using APIs from this course at all, having to instead scrounge up my own resources in the absence of any meaningful educational material on the subject from Udacity. 

Similar to my comments on the Practical Statistics class, I again got the feeling that this was an older class that has not yet been redesigned to meet the levels of polish that I've seen in some of my other Udacity courses. However, where this is different from the Practical Statistics class is that I do think that this course can be saved. The biggest and most intractable problems were all related to the data gathering portion of the course, which could be significantly redesigned without impacting the rest of the course. This could be done to provide a longer and more natural progression for students from basic scraping/API usage to more complex operations, and in doing so could give students some hands-on time with the json and tweepy libraries so that these are not wildly new concepts and packages upon reaching the project. These sorts of changes would tremendously improve this class and the associated project, such that this could easily be one of the best online courses that I've taken, rather than one of the worst. 